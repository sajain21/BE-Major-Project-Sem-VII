{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pdfminer\\pdfdocument.py:22: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilesh \n",
      "Dhondiba \n",
      "Virkar \n",
      "\n",
      "Balkum pada no 3 , Thane (W) \n",
      "9137858211 \n",
      "Nileshvirkar2000@gmail.com \n",
      "https://www.linkedin.com/in/niles \n",
      "h-virkar-37118b246 \n",
      "\n",
      "Education \n",
      "  A.P Shah Institute of Technology / Bachelor of Engineering \n",
      "\n",
      "In Information Technology with 8.21 CGPA (Pursuing) \n",
      "\n",
      "  Government Polytechnic Thane(Diploma IT) \n",
      "\n",
      "Diploma  in Information Technology with an aggregate of 66.18% \n",
      "\n",
      "  Shivai vidya mandir (10th) \n",
      "\n",
      "Graduated School with an aggregate of 70% \n",
      "\n",
      "2019-2023 \n",
      "\n",
      "2016-2019 \n",
      "\n",
      "2015-2016 \n",
      "\n",
      "Skills \n",
      "  Programming Language Known: Python, C++,  C, Java. \n",
      "  Framework: react.Js \n",
      "  Database: MySQL. \n",
      "  Language Known: Marathi, English, Hindi  \n",
      "\n",
      "Projects \n",
      "  Chatbot for Healthcare using Machine Learning – Academic Project \n",
      "\n",
      "A chatbot which replies according to the user's question by predicting the reply from \n",
      "pre-trained data. Machine Learning Code was done by using Python, Flask, Numpy, and NLT \n",
      "libraries with PyTorch. \n",
      "\n",
      "  Blood Bank Management System – Academic Project - \n",
      "\n",
      "A website for blood donation and requesting blood, the front end was made using \n",
      "\n",
      "reactjs and the backend with Mysql as the database. \n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\fVIRTUAL INTERNSHIPS \n",
      "\n",
      "  APSIT SKILLS INTERNSHIP. \n",
      "\n",
      "AICTE Internships \n",
      "\n",
      "  Cyber security Foundation. \n",
      "\n",
      "Palo Alto Networks, Cyber security Academy \n",
      "\n",
      "  Cloud Architecting. \n",
      "\n",
      "AWS, AWS Academy \n",
      "\n",
      "Certificates \n",
      "  C for everyone \n",
      "\n",
      "Coursera, Project Network \n",
      "\n",
      "  Database Management Essentials \n",
      "Coursera, University of Colorado \n",
      "\n",
      "  Python Data Structures \n",
      "\n",
      "Coursera, University of Michigan \n",
      "\n",
      "  Cyber security Foundation \n",
      "\n",
      "Palo Alto Networks, Cyber security Academy \n",
      "\n",
      "  Cloud Foundations \n",
      "\n",
      "AWS, AWS Academy \n",
      "\n",
      " \n",
      "\n",
      "IoT Fundamentals: Connecting Things \n",
      "Cisco, Cisco Networking Academy \n",
      "\n",
      "  Cloud Architecting \n",
      "\n",
      "AWS, AWS Academy \n",
      "\n",
      "  Networking Essentials \n",
      "\n",
      "Cisco, Cisco Networking Academy \n",
      "\n",
      "Extra-curricular \n",
      "  SAP Institute Name: Government Polytechnic Thane, \n",
      "\n",
      "I have learnt basic introduction to SAP through this workshop \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Inter-college sports and cultural committee coordinator \n",
      "\n",
      "Inter-college sports committee team manager – IT Department \n",
      "\n",
      "Inter-college cultural event security head \n",
      "\n",
      "2020 \n",
      "\n",
      "2021 \n",
      "\n",
      "2022 \n",
      "\n",
      "2020 \n",
      "\n",
      "2020 \n",
      "\n",
      "2020 \n",
      "\n",
      "2021 \n",
      "\n",
      "2021 \n",
      "\n",
      "2022 \n",
      "\n",
      "2022 \n",
      "\n",
      "2022 \n",
      "\n",
      " \n",
      " \n",
      "\fInterest \n",
      "  Web Development \n",
      "  Fitness freak \n",
      "  Kabbadi \n",
      "\n",
      " \n",
      " \n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example_01.py\n",
    " \n",
    "from pdfminer.high_level import extract_text\n",
    " \n",
    " \n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    print(extract_text_from_pdf('./resume.pdf'))  # noqa: T001\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balkum pada no 3 , Thane (W)\n",
      "\n",
      "9137858211\n",
      "\n",
      "Nileshvirkar2000@gmail.com\n",
      "\n",
      "https://www.linkedin.com/in/niles\n",
      "\n",
      "h-virkar-37118b246\n",
      "\n",
      "Nilesh Dhondiba Virkar\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Education\n",
      "\n",
      "   A.P Shah Institute of Technology / Bachelor of Engineering 2019-2023\n",
      "\n",
      "In Information Technology with 8.21 CGPA (Pursuing)\n",
      "\n",
      "   Government Polytechnic Thane(Diploma IT) 2016-2019\n",
      "\n",
      "Diploma in Information Technology with an aggregate of 66.18%\n",
      "\n",
      "   Shivai vidya mandir (10th) 2015-2016\n",
      "\n",
      "Graduated School with an aggregate of 70%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skills\n",
      "\n",
      "  Programming Language Known: Python, C++, C, Java.\n",
      "\n",
      "  Framework: react.Js\n",
      "\n",
      "  Database: MySQL.\n",
      "\n",
      "  Language Known: Marathi, English, Hindi \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Projects\n",
      "\n",
      "  Chatbot for Healthcare using Machine Learning – Academic Project\n",
      "\n",
      "A chatbot which replies according to the user's question by predicting the reply from pre-trained data. Machine Learning Code was done by using Python, Flask, Numpy, and NLT libraries with PyTorch.\n",
      "\n",
      "\n",
      "\n",
      "  Blood Bank Management System – Academic Project -\n",
      "\n",
      "A website for blood donation and requesting blood, the front end was made using reactjs and the backend with Mysql as the database.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "VIRTUAL INTERNSHIPS\n",
      "\n",
      "   APSIT SKILLS INTERNSHIP. 2020\n",
      "\n",
      "AICTE Internships\n",
      "\n",
      "   Cyber security Foundation. 2021\n",
      "\n",
      "Palo Alto Networks, Cyber security Academy\n",
      "\n",
      "   Cloud Architecting. 2022\n",
      "\n",
      "AWS, AWS Academy\n",
      "\n",
      "Certificates\n",
      "\n",
      "   C for everyone 2020\n",
      "\n",
      "Coursera, Project Network\n",
      "\n",
      "   Database Management Essentials 2020\n",
      "\n",
      "Coursera, University of Colorado\n",
      "\n",
      "   Python Data Structures 2020\n",
      "\n",
      "Coursera, University of Michigan\n",
      "\n",
      "   Cyber security Foundation 2021\n",
      "\n",
      "Palo Alto Networks, Cyber security Academy\n",
      "\n",
      "   Cloud Foundations 2021\n",
      "\n",
      "AWS, AWS Academy\n",
      "\n",
      "   IoT Fundamentals: Connecting Things 2022\n",
      "\n",
      "Cisco, Cisco Networking Academy\n",
      "\n",
      "   Cloud Architecting 2022\n",
      "\n",
      "AWS, AWS Academy\n",
      "\n",
      "   Networking Essentials 2022\n",
      "\n",
      "Cisco, Cisco Networking Academy\n",
      "\n",
      "\n",
      "\n",
      "Extra-curricular\n",
      "\n",
      "  SAP Institute Name: Government Polytechnic Thane,\n",
      "\n",
      "I have learnt basic introduction to SAP through this workshop\n",
      "\n",
      "  Inter-college sports and cultural committee coordinator\n",
      "\n",
      "  Inter-college sports committee team manager – IT Department\n",
      "\n",
      "  Inter-college cultural event security head\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Interest\n",
      "\n",
      "  Web Development\n",
      "\n",
      "  Fitness freak\n",
      "\n",
      "  Kabbadi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example_02.py\n",
    " \n",
    "import docx2txt\n",
    " \n",
    " \n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    print(extract_text_from_docx('./resume.docx'))  # noqa: T001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilesh Dhondiba Virkar Education\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example_04.py\n",
    " \n",
    "import docx2txt\n",
    "import nltk\n",
    " \n",
    " \n",
    " \n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    " \n",
    " \n",
    "def extract_names(txt):\n",
    "    person_names = []\n",
    " \n",
    "    for sent in nltk.sent_tokenize(txt):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
    "                person_names.append(\n",
    "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
    "                )\n",
    " \n",
    "    return person_names\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_docx('resume.docx')\n",
    "    names = extract_names(text)\n",
    " \n",
    "    if names:\n",
    "        print(names[0])  # noqa: T001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ileshvirkar2000@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# example_06.py\n",
    " \n",
    "import re\n",
    " \n",
    "from pdfminer.high_level import extract_text\n",
    " \n",
    "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
    " \n",
    " \n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    " \n",
    " \n",
    "def extract_emails(resume_text):\n",
    "    return re.findall(EMAIL_REG, resume_text)\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_pdf('resume.pdf')\n",
    "    emails = extract_emails(text)\n",
    " \n",
    "    if emails:\n",
    "        print(emails[0])  # noqa: T001\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Python', 'Machine Learning'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\priya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "import nltk\n",
    " \n",
    "nltk.download('stopwords')\n",
    " \n",
    "# you may read the database from a csv file or some other database\n",
    "SKILLS_DB = [\n",
    "    'machine learning',\n",
    "    'data science',\n",
    "    'python',\n",
    "    'word',\n",
    "    'excel',\n",
    "    'English',\n",
    "]\n",
    " \n",
    " \n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    " \n",
    " \n",
    "def extract_skills(input_text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    " \n",
    "    # remove the stop words\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    " \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "    found_skills = set()\n",
    " \n",
    "    # we search for each token in our skills database\n",
    "    for token in filtered_tokens:\n",
    "        if token.lower() in SKILLS_DB:\n",
    "            found_skills.add(token)\n",
    " \n",
    "    # we search for each bigram and trigram in our skills database\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram.lower() in SKILLS_DB:\n",
    "            found_skills.add(ngram)\n",
    " \n",
    "    return found_skills\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_docx('resume.docx')\n",
    "    skills = extract_skills(text)\n",
    " \n",
    "    print(skills)  # noqa: T001\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef03d38a89891b0d19aaba5df3ac56da910424ab49b1b82add7b7e5503259d62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
