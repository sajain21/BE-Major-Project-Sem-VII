{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('train_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
       " {'entities': [(1749, 1755, 'Companies worked at'),\n",
       "   (1696, 1702, 'Companies worked at'),\n",
       "   (1417, 1423, 'Companies worked at'),\n",
       "   (1356, 1793, 'Skills'),\n",
       "   (1209, 1215, 'Companies worked at'),\n",
       "   (1136, 1248, 'Skills'),\n",
       "   (928, 932, 'Graduation Year'),\n",
       "   (858, 889, 'College Name'),\n",
       "   (821, 856, 'Degree'),\n",
       "   (787, 791, 'Graduation Year'),\n",
       "   (744, 750, 'Companies worked at'),\n",
       "   (722, 742, 'Designation'),\n",
       "   (658, 664, 'Companies worked at'),\n",
       "   (640, 656, 'Designation'),\n",
       "   (574, 580, 'Companies worked at'),\n",
       "   (555, 573, 'Designation'),\n",
       "   (470, 493, 'Companies worked at'),\n",
       "   (444, 469, 'Designation'),\n",
       "   (308, 314, 'Companies worked at'),\n",
       "   (234, 240, 'Companies worked at'),\n",
       "   (175, 198, 'Companies worked at'),\n",
       "   (93, 137, 'Email Address'),\n",
       "   (39, 48, 'Location'),\n",
       "   (13, 38, 'Designation'),\n",
       "   (0, 12, 'Name')]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "def train_model(train_data):\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last = True)\n",
    "    \n",
    "    for _, annotation in train_data:\n",
    "        for ent in annotation['entities']:\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            index = 0\n",
    "            for text, annotations in train_data:\n",
    "                try:\n",
    "                    nlp.update(\n",
    "                        [text],  # batch of texts\n",
    "                        [annotations],  # batch of annotations\n",
    "                        drop=0.2,  # dropout - make it harder to memorise data\n",
    "                        sgd=optimizer,  # callable to update weights\n",
    "                        losses=losses)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "            print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x00000233553169D0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(train_data)\n",
      "Cell \u001b[1;32mIn [7], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mner\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m nlp\u001b[39m.\u001b[39mpipe_names:\n\u001b[0;32m      5\u001b[0m     ner \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mcreate_pipe(\u001b[39m'\u001b[39m\u001b[39mner\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     nlp\u001b[39m.\u001b[39;49madd_pipe(ner, last \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m _, annotation \u001b[39min\u001b[39;00m train_data:\n\u001b[0;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m annotation[\u001b[39m'\u001b[39m\u001b[39mentities\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:773\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    771\u001b[0m     bad_val \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(factory_name)\n\u001b[0;32m    772\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE966\u001b[39m.\u001b[39mformat(component\u001b[39m=\u001b[39mbad_val, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    774\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m factory_name\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_names:\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x00000233553169D0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "train_model(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84acd9daa1976748b0cb1aac2d1d7e831b987877e0682bbd8df981985727d27e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
